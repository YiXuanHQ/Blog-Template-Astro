---
title: NLP å…¥é—¨
nextChapter: "python-ai/nlp/02-æ–‡æœ¬é¢„å¤„ç†"
parentChapter: "python-ai/nlp/README"
---
# NLP å…¥é—¨

> äº†è§£è‡ªç„¶è¯­è¨€å¤„ç†ï¼Œå¼€å¯NLPå­¦ä¹ ä¹‹æ—…

## ğŸ“š å­¦ä¹ ç›®æ ‡

- ç†è§£ä»€ä¹ˆæ˜¯NLP
- äº†è§£NLPçš„åº”ç”¨åœºæ™¯
- æŒæ¡NLPä¸»è¦ä»»åŠ¡
- å­¦ä¼šç¯å¢ƒæ­å»º
- è¿è¡Œç¬¬ä¸€ä¸ªNLPç¨‹åº

## 1. ä»€ä¹ˆæ˜¯NLP

### 1.1 å®šä¹‰

**è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNatural Language Processingï¼ŒNLPï¼‰** æ˜¯è®¡ç®—æœºç§‘å­¦ã€äººå·¥æ™ºèƒ½å’Œè¯­è¨€å­¦çš„äº¤å‰é¢†åŸŸï¼Œè‡´åŠ›äºè®©è®¡ç®—æœºç†è§£ã€å¤„ç†å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚

### 1.2 ä¸ºä»€ä¹ˆéœ€è¦NLP

- äººç±»è¯­è¨€æ˜¯æœ€è‡ªç„¶çš„äº¤äº’æ–¹å¼
- æµ·é‡æ–‡æœ¬æ•°æ®éœ€è¦è‡ªåŠ¨å¤„ç†
- è·¨è¯­è¨€äº¤æµéœ€æ±‚
- æ™ºèƒ½åŒ–æœåŠ¡éœ€æ±‚

### 1.3 NLPçš„æŒ‘æˆ˜

- **æ­§ä¹‰æ€§** - ä¸€è¯å¤šä¹‰ã€å¥æ³•æ­§ä¹‰
- **ä¸Šä¸‹æ–‡ä¾èµ–** - ç†è§£éœ€è¦ä¸Šä¸‹æ–‡
- **è¯­è¨€å¤šæ ·æ€§** - ä¸åŒè¯­è¨€å·®å¼‚å¤§
- **éšå«ä¿¡æ¯** - è®½åˆºã€æ¯”å–»ç­‰
- **é•¿è·ç¦»ä¾èµ–** - è¿œè·ç¦»è¯æ±‡å…³è”

## 2. NLP åº”ç”¨åœºæ™¯

### 2.1 æ—¥å¸¸åº”ç”¨

```python
# æœç´¢å¼•æ“
query = "åŒ—äº¬å¤©æ°”"
# -> ç†è§£ç”¨æˆ·æ„å›¾ï¼Œè¿”å›ç›¸å…³ç»“æœ

# è¯­éŸ³åŠ©æ‰‹
command = "æ˜å¤©æé†’æˆ‘å¼€ä¼š"
# -> è¯­éŸ³è¯†åˆ« + æ„å›¾ç†è§£ + ä»»åŠ¡æ‰§è¡Œ

# æœºå™¨ç¿»è¯‘
text = "Hello World"
# -> ç¿»è¯‘ä¸º "ä½ å¥½ä¸–ç•Œ"

# æ™ºèƒ½å®¢æœ
question = "æ€ä¹ˆé€€è´§ï¼Ÿ"
# -> æ„å›¾è¯†åˆ« + çŸ¥è¯†æ£€ç´¢ + å›å¤ç”Ÿæˆ
```

### 2.2 å•†ä¸šåº”ç”¨

- **ç”µå•†** - å•†å“æœç´¢ã€è¯„è®ºåˆ†æã€æ¨èç³»ç»Ÿ
- **é‡‘è** - èˆ†æƒ…ç›‘æ§ã€é£é™©é¢„è­¦ã€æ™ºèƒ½æŠ•é¡¾
- **åŒ»ç–—** - ç—…å†åˆ†æã€æ–‡çŒ®æ£€ç´¢ã€è¾…åŠ©è¯Šæ–­
- **æ³•å¾‹** - åˆåŒå®¡æŸ¥ã€æ¡ˆä¾‹æ£€ç´¢ã€æ³•å¾‹å’¨è¯¢
- **æ•™è‚²** - è‡ªåŠ¨æ‰¹æ”¹ã€æ™ºèƒ½é—®ç­”ã€ä¸ªæ€§åŒ–å­¦ä¹ 

## 3. NLP ä¸»è¦ä»»åŠ¡

### 3.1 æ–‡æœ¬ç†è§£

```python
# 1. åˆ†è¯
text = "æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†"
tokens = ["æˆ‘", "çˆ±", "è‡ªç„¶è¯­è¨€å¤„ç†"]

# 2. è¯æ€§æ ‡æ³¨
# æˆ‘/ä»£è¯ çˆ±/åŠ¨è¯ è‡ªç„¶è¯­è¨€å¤„ç†/åè¯

# 3. å‘½åå®ä½“è¯†åˆ«
text = "è‹¹æœå…¬å¸CEOåº“å…‹è®¿é—®ä¸­å›½"
entities = {
    "è‹¹æœå…¬å¸": "ç»„ç»‡",
    "åº“å…‹": "äººå",
    "ä¸­å›½": "åœ°å"
}

# 4. æƒ…æ„Ÿåˆ†æ
text = "è¿™éƒ¨ç”µå½±å¤ªå¥½çœ‹äº†ï¼"
sentiment = "positive"  # æ­£é¢

# 5. æ–‡æœ¬åˆ†ç±»
text = "ç§‘æŠ€å·¨å¤´å‘å¸ƒæ–°äº§å“"
category = "ç§‘æŠ€"
```

### 3.2 æ–‡æœ¬ç”Ÿæˆ

```python
# 1. æœºå™¨ç¿»è¯‘
source = "I love programming"
target = "æˆ‘çˆ±ç¼–ç¨‹"

# 2. æ–‡æœ¬æ‘˜è¦
article = "é•¿ç¯‡æ–‡ç« å†…å®¹..."
summary = "ç®€çŸ­æ‘˜è¦"

# 3. å¯¹è¯ç”Ÿæˆ
user = "ä½ å¥½"
bot = "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼Ÿ"

# 4. æ–‡æœ¬ç»­å†™
prompt = "ä»å‰æœ‰åº§å±±ï¼Œ"
completion = "å±±ä¸Šæœ‰åº§åº™"
```

## 4. ç¯å¢ƒæ­å»º

### 4.1 å®‰è£…Pythonåº“

```bash
# åŸºç¡€ç§‘å­¦è®¡ç®—
pip install numpy pandas matplotlib

# ä¸­æ–‡NLP
pip install jieba          # ä¸­æ–‡åˆ†è¯
pip install pkuseg         # åŒ—å¤§åˆ†è¯
pip install snownlp        # ä¸­æ–‡æƒ…æ„Ÿåˆ†æ

# è‹±æ–‡NLP
pip install nltk           # ç»å…¸NLPåº“
pip install spacy          # å·¥ä¸šçº§NLP

# è¯å‘é‡
pip install gensim         # Word2Vecç­‰

# æ·±åº¦å­¦ä¹ 
pip install torch          # PyTorch
pip install transformers   # Hugging Faceæ¨¡å‹

# å…¶ä»–å·¥å…·
pip install scikit-learn   # æœºå™¨å­¦ä¹ 
pip install wordcloud      # è¯äº‘
```

### 4.2 ä¸‹è½½è¯­æ–™å’Œæ¨¡å‹

```python
# NLTK æ•°æ®
import nltk
nltk.download('punkt')
nltk.download('stopwords')

# spaCy æ¨¡å‹
# python -m spacy download zh_core_web_sm  # ä¸­æ–‡
# python -m spacy download en_core_web_sm  # è‹±æ–‡
```

## 5. ç¬¬ä¸€ä¸ªNLPç¨‹åº

### 5.1 ä¸­æ–‡åˆ†è¯

```python
import jieba

# ç²¾ç¡®æ¨¡å¼
text = "æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦"
seg_list = jieba.cut(text, cut_all=False)
print("ç²¾ç¡®æ¨¡å¼:", "/ ".join(seg_list))
# è¾“å‡º: æˆ‘/ æ¥åˆ°/ åŒ—äº¬/ æ¸…åå¤§å­¦

# å…¨æ¨¡å¼
seg_list = jieba.cut(text, cut_all=True)
print("å…¨æ¨¡å¼:", "/ ".join(seg_list))
# è¾“å‡º: æˆ‘/ æ¥åˆ°/ åŒ—äº¬/ æ¸…å/ æ¸…åå¤§å­¦/ åå¤§/ å¤§å­¦

# æœç´¢å¼•æ“æ¨¡å¼
seg_list = jieba.cut_for_search(text)
print("æœç´¢å¼•æ“æ¨¡å¼:", "/ ".join(seg_list))
```

### 5.2 è¯æ€§æ ‡æ³¨

```python
import jieba.posseg as pseg

text = "æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†"
words = pseg.cut(text)

for word, flag in words:
    print(f"{word}\t{flag}")

# è¾“å‡º:
# æˆ‘      r (ä»£è¯)
# çˆ±      v (åŠ¨è¯)
# è‡ªç„¶è¯­è¨€å¤„ç†  l (ä¹ ç”¨è¯­)
```

### 5.3 å…³é”®è¯æå–

```python
import jieba.analyse

text = """
è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯è®¡ç®—æœºç§‘å­¦é¢†åŸŸä¸äººå·¥æ™ºèƒ½é¢†åŸŸä¸­çš„ä¸€ä¸ªé‡è¦æ–¹å‘ã€‚
å®ƒç ”ç©¶èƒ½å®ç°äººä¸è®¡ç®—æœºä¹‹é—´ç”¨è‡ªç„¶è¯­è¨€è¿›è¡Œæœ‰æ•ˆé€šä¿¡çš„å„ç§ç†è®ºå’Œæ–¹æ³•ã€‚
"""

# TF-IDF
keywords = jieba.analyse.extract_tags(text, topK=5)
print("å…³é”®è¯:", keywords)

# TextRank
keywords = jieba.analyse.textrank(text, topK=5)
print("å…³é”®è¯:", keywords)
```

### 5.4 æƒ…æ„Ÿåˆ†æ

```python
from snownlp import SnowNLP

text = "è¿™ä¸ªç”µå½±çœŸçš„å¤ªå¥½çœ‹äº†ï¼Œå¼ºçƒˆæ¨èï¼"
s = SnowNLP(text)

print(f"æƒ…æ„Ÿå¾—åˆ†: {s.sentiments}")  # 0-1ä¹‹é—´ï¼Œè¶Šæ¥è¿‘1è¶Šç§¯æ
# è¾“å‡º: æƒ…æ„Ÿå¾—åˆ†: 0.97

if s.sentiments > 0.6:
    print("æ­£é¢è¯„ä»·")
elif s.sentiments < 0.4:
    print("è´Ÿé¢è¯„ä»·")
else:
    print("ä¸­æ€§è¯„ä»·")
```

## 6. è‹±æ–‡NLPç¤ºä¾‹

### 6.1 ä½¿ç”¨NLTK

```python
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

text = "Natural Language Processing is awesome!"

# åˆ†è¯
tokens = word_tokenize(text)
print("Tokens:", tokens)

# å»é™¤åœç”¨è¯
stop_words = set(stopwords.words('english'))
filtered = [w for w in tokens if w.lower() not in stop_words]
print("Filtered:", filtered)
```

### 6.2 ä½¿ç”¨spaCy

```python
import spacy

# åŠ è½½æ¨¡å‹
nlp = spacy.load("en_core_web_sm")

text = "Apple is looking at buying U.K. startup for $1 billion"
doc = nlp(text)

# å‘½åå®ä½“è¯†åˆ«
for ent in doc.ents:
    print(f"{ent.text}\t{ent.label_}")

# è¾“å‡º:
# Apple           ORG (ç»„ç»‡)
# U.K.            GPE (åœ°ç†æ”¿æ²»å®ä½“)
# $1 billion      MONEY (é‡‘é¢)
```

## 7. NLP æŠ€æœ¯æ ˆ

### 7.1 æŠ€æœ¯å±‚æ¬¡

```
åº”ç”¨å±‚
â”œâ”€ æœç´¢å¼•æ“
â”œâ”€ æ™ºèƒ½å®¢æœ
â”œâ”€ æœºå™¨ç¿»è¯‘
â””â”€ å†…å®¹æ¨è

ç®—æ³•å±‚
â”œâ”€ æ·±åº¦å­¦ä¹  (Transformer, BERT, GPT)
â”œâ”€ æœºå™¨å­¦ä¹  (SVM, æœ´ç´ è´å¶æ–¯)
â””â”€ è§„åˆ™æ–¹æ³•

ç‰¹å¾å±‚
â”œâ”€ è¯å‘é‡ (Word2Vec, GloVe)
â”œâ”€ TF-IDF
â””â”€ è¯è¢‹æ¨¡å‹

åŸºç¡€å±‚
â”œâ”€ åˆ†è¯
â”œâ”€ è¯æ€§æ ‡æ³¨
â””â”€ å‘½åå®ä½“è¯†åˆ«
```

### 7.2 å‘å±•å†ç¨‹

- **1950s** - æœºå™¨ç¿»è¯‘èµ·æ­¥
- **1980s** - ç»Ÿè®¡æ–¹æ³•å…´èµ·
- **2000s** - æœºå™¨å­¦ä¹ åº”ç”¨
- **2013** - Word2Vec è¯å‘é‡
- **2017** - Transformer æ¶æ„
- **2018** - BERT é¢„è®­ç»ƒæ¨¡å‹
- **2020** - GPT-3 å¤§æ¨¡å‹
- **2022** - ChatGPT å¯¹è¯æ¨¡å‹

## 8. å¸¸è§é—®é¢˜

### Q1: ä¸­æ–‡å’Œè‹±æ–‡NLPæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**ä¸­æ–‡ç‰¹ç‚¹:**
- æ²¡æœ‰ç©ºæ ¼åˆ†éš”ï¼Œéœ€è¦åˆ†è¯
- å­—ã€è¯ã€çŸ­è¯­æ¦‚å¿µ
- è¯­åºç›¸å¯¹çµæ´»

**è‹±æ–‡ç‰¹ç‚¹:**
- è‡ªç„¶ç©ºæ ¼åˆ†éš”
- å½¢æ€å˜åŒ–ä¸°å¯Œ
- è¯­åºç›¸å¯¹å›ºå®š

### Q2: å¦‚ä½•é€‰æ‹©ä¸­æ–‡åˆ†è¯å·¥å…·ï¼Ÿ

- **jieba** - æœ€æµè¡Œï¼Œç®€å•æ˜“ç”¨
- **pkuseg** - å‡†ç¡®ç‡é«˜ï¼Œé€Ÿåº¦è¾ƒæ…¢
- **thulac** - æ¸…åå¼€å‘ï¼Œæ•ˆæœå¥½
- **HanLP** - åŠŸèƒ½å…¨é¢

### Q3: éœ€è¦GPUå—ï¼Ÿ

- **ä¼ ç»Ÿæ–¹æ³•** - ä¸éœ€è¦ï¼ˆåˆ†è¯ã€TF-IDFç­‰ï¼‰
- **æ·±åº¦å­¦ä¹ ** - å»ºè®®ä½¿ç”¨ï¼ˆBERTã€GPTç­‰ï¼‰

## 9. ç»ƒä¹ é¢˜

1. ä½¿ç”¨jiebaå¯¹ä¸€æ®µä¸­æ–‡è¿›è¡Œåˆ†è¯
2. æå–æ–‡æœ¬çš„å…³é”®è¯ï¼ˆå‰5ä¸ªï¼‰
3. åˆ†æä¸€æ®µè¯„è®ºçš„æƒ…æ„Ÿå€¾å‘
4. ä½¿ç”¨NLTKå¤„ç†è‹±æ–‡æ–‡æœ¬

## 10. å­¦ä¹ èµ„æº

### åœ¨çº¿æ•™ç¨‹
- [NLTK Book](https://www.nltk.org/book/)
- [spaCy Course](https://course.spacy.io/)

### ä¸­æ–‡èµ„æº
- jieba GitHubæ–‡æ¡£
- å“ˆå·¥å¤§LTP
- åŒ—å¤§NLPå®éªŒå®¤

## ğŸ’¡ é‡ç‚¹æ€»ç»“

1. **NLP** è®©è®¡ç®—æœºç†è§£å’Œå¤„ç†äººç±»è¯­è¨€
2. **åº”ç”¨å¹¿æ³›** - æœç´¢ã€ç¿»è¯‘ã€å®¢æœã€æ¨èç­‰
3. **ä¸»è¦ä»»åŠ¡** - åˆ†è¯ã€åˆ†ç±»ã€NERã€ç”Ÿæˆç­‰
4. **å·¥å…·åº“** - jiebaã€NLTKã€spaCyã€transformers
5. **å‘å±•è¶‹åŠ¿** - é¢„è®­ç»ƒæ¨¡å‹ã€å¤§è¯­è¨€æ¨¡å‹

---

**ä¸‹ä¸€èŠ‚ï¼š** [æ–‡æœ¬é¢„å¤„ç†](02-æ–‡æœ¬é¢„å¤„ç†.md)
