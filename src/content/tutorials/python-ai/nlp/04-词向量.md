---
title: è¯å‘é‡
prevChapter: "python-ai/nlp/03-ä¸­æ–‡åˆ†è¯"
nextChapter: "python-ai/nlp/05-æ–‡æœ¬åˆ†ç±»"
parentChapter: "python-ai/nlp/README"
---
# è¯å‘é‡

> æŒæ¡è¯å‘é‡è¡¨ç¤ºå’Œåº”ç”¨

## ğŸ“š å­¦ä¹ ç›®æ ‡

- ç†è§£è¯å‘é‡æ¦‚å¿µ
- æŒæ¡TF-IDF
- å­¦ä¼šWord2Vec
- äº†è§£GloVeå’ŒFastText

## 1. è¯è¢‹æ¨¡å‹

```python
from sklearn.feature_extraction.text import CountVectorizer

corpus = [
    'æˆ‘ çˆ± è‡ªç„¶è¯­è¨€å¤„ç†',
    'æ·±åº¦å­¦ä¹  å¾ˆ æœ‰è¶£',
    'è‡ªç„¶è¯­è¨€å¤„ç† ä½¿ç”¨ æ·±åº¦å­¦ä¹ '
]

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(corpus)

print("è¯æ±‡è¡¨:", vectorizer.get_feature_names_out())
print("å‘é‡:\n", X.toarray())
```

## 2. TF-IDF

```python
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer()
X = tfidf.fit_transform(corpus)

print("TF-IDF:\n", X.toarray())

# æŸ¥çœ‹ç‰¹å¾æƒé‡
feature_names = tfidf.get_feature_names_out()
for doc_idx, doc in enumerate(X.toarray()):
    print(f"\næ–‡æ¡£ {doc_idx}:")
    for idx, score in enumerate(doc):
        if score > 0:
            print(f"  {feature_names[idx]}: {score:.4f}")
```

## 3. Word2Vec

```python
from gensim.models import Word2Vec
import jieba

# å‡†å¤‡æ•°æ®
sentences = [
    list(jieba.cut("æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†")),
    list(jieba.cut("æ·±åº¦å­¦ä¹ å¾ˆæœ‰è¶£")),
    list(jieba.cut("æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„åˆ†æ”¯"))
]

# è®­ç»ƒæ¨¡å‹
model = Word2Vec(sentences, 
                 vector_size=100,  # è¯å‘é‡ç»´åº¦
                 window=5,         # ä¸Šä¸‹æ–‡çª—å£
                 min_count=1,      # æœ€å°è¯é¢‘
                 workers=4)        # çº¿ç¨‹æ•°

# è·å–è¯å‘é‡
vector = model.wv['è‡ªç„¶è¯­è¨€å¤„ç†']
print("è¯å‘é‡:", vector[:10])

# ç›¸ä¼¼è¯
similar = model.wv.most_similar('æ·±åº¦å­¦ä¹ ', topn=5)
print("ç›¸ä¼¼è¯:", similar)

# è¯è¯­ç›¸ä¼¼åº¦
similarity = model.wv.similarity('æ·±åº¦å­¦ä¹ ', 'æœºå™¨å­¦ä¹ ')
print("ç›¸ä¼¼åº¦:", similarity)

# ä¿å­˜å’ŒåŠ è½½
model.save('word2vec.model')
model = Word2Vec.load('word2vec.model')
```

## 4. ä½¿ç”¨é¢„è®­ç»ƒè¯å‘é‡

```python
from gensim.models import KeyedVectors

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
# ä¸‹è½½: https://github.com/Embedding/Chinese-Word-Vectors
model = KeyedVectors.load_word2vec_format('sgns.wiki.word', binary=False)

# ä½¿ç”¨
vector = model['ä¸­å›½']
similar = model.most_similar('ä¸­å›½', topn=10)
```

## 5. FastText

```python
from gensim.models import FastText

# è®­ç»ƒFastText
model = FastText(sentences, 
                 vector_size=100,
                 window=5,
                 min_count=1)

# è·å–è¯å‘é‡ï¼ˆåŒ…æ‹¬æœªç™»å½•è¯ï¼‰
vector = model.wv['æœªç™»å½•è¯']
```

---

**ä¸‹ä¸€èŠ‚ï¼š** [æ–‡æœ¬åˆ†ç±»](05-æ–‡æœ¬åˆ†ç±».md)
