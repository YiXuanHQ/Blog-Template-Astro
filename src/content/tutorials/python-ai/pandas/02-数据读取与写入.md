---
title: æ•°æ®è¯»å–ä¸å†™å…¥
prevChapter: "python-ai/pandas/01-Pandaså…¥é—¨"
nextChapter: "python-ai/pandas/03-æ•°æ®é€‰æ‹©ä¸ç´¢å¼•"
parentChapter: "python-ai/pandas/README"
---
# æ•°æ®è¯»å–ä¸å†™å…¥

> æŒæ¡Pandasçš„æ•°æ®IOæ“ä½œ

## ğŸ“š å­¦ä¹ ç›®æ ‡

- æŒæ¡CSVæ–‡ä»¶çš„è¯»å†™
- å­¦ä¼šExcelæ–‡ä»¶æ“ä½œ
- æŒæ¡JSONæ•°æ®å¤„ç†
- å­¦ä¼šæ•°æ®åº“æ“ä½œ
- äº†è§£å…¶ä»–æ ¼å¼

## 1. CSVæ–‡ä»¶

### 1.1 è¯»å–CSV

```python
import pandas as pd

# åŸºæœ¬è¯»å–
df = pd.read_csv('data.csv')

# æŒ‡å®šåˆ†éš”ç¬¦
df = pd.read_csv('data.txt', sep='\t')

# æŒ‡å®šç¼–ç 
df = pd.read_csv('data.csv', encoding='utf-8')

# æŒ‡å®šç´¢å¼•åˆ—
df = pd.read_csv('data.csv', index_col=0)

# æŒ‡å®šåˆ—å
df = pd.read_csv('data.csv', names=['col1', 'col2', 'col3'])

# è·³è¿‡è¡Œ
df = pd.read_csv('data.csv', skiprows=[0, 2])  # è·³è¿‡ç¬¬1å’Œç¬¬3è¡Œ

# åªè¯»å–éƒ¨åˆ†è¡Œ
df = pd.read_csv('data.csv', nrows=1000)

# æŒ‡å®šæ•°æ®ç±»å‹
df = pd.read_csv('data.csv', dtype={'age': int, 'name': str})

# å¤„ç†ç¼ºå¤±å€¼
df = pd.read_csv('data.csv', na_values=['NA', 'null', ''])

# è§£ææ—¥æœŸ
df = pd.read_csv('data.csv', parse_dates=['date_column'])
```

### 1.2 å†™å…¥CSV

```python
# åŸºæœ¬å†™å…¥
df.to_csv('output.csv')

# ä¸å†™å…¥ç´¢å¼•
df.to_csv('output.csv', index=False)

# æŒ‡å®šåˆ†éš”ç¬¦
df.to_csv('output.txt', sep='\t')

# æŒ‡å®šç¼–ç 
df.to_csv('output.csv', encoding='utf-8')

# åªå†™å…¥éƒ¨åˆ†åˆ—
df.to_csv('output.csv', columns=['col1', 'col2'])

# è¿½åŠ æ¨¡å¼
df.to_csv('output.csv', mode='a', header=False)
```

## 2. Excelæ–‡ä»¶

### 2.1 è¯»å–Excel

```python
# éœ€è¦å®‰è£…ï¼špip install openpyxl

# è¯»å–Excel
df = pd.read_excel('data.xlsx')

# æŒ‡å®šå·¥ä½œè¡¨
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')

# è¯»å–å¤šä¸ªå·¥ä½œè¡¨
dfs = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])

# è¯»å–æ‰€æœ‰å·¥ä½œè¡¨
dfs = pd.read_excel('data.xlsx', sheet_name=None)

# æŒ‡å®šè¡Œå’Œåˆ—
df = pd.read_excel('data.xlsx', usecols='A:C', skiprows=2)
```

### 2.2 å†™å…¥Excel

```python
# å†™å…¥Excel
df.to_excel('output.xlsx', index=False)

# å†™å…¥å¤šä¸ªå·¥ä½œè¡¨
with pd.ExcelWriter('output.xlsx') as writer:
    df1.to_excel(writer, sheet_name='Sheet1', index=False)
    df2.to_excel(writer, sheet_name='Sheet2', index=False)

# è¿½åŠ åˆ°ç°æœ‰æ–‡ä»¶
with pd.ExcelWriter('output.xlsx', mode='a') as writer:
    df.to_excel(writer, sheet_name='NewSheet')
```

## 3. JSONæ–‡ä»¶

### 3.1 è¯»å–JSON

```python
# è¯»å–JSONæ–‡ä»¶
df = pd.read_json('data.json')

# æŒ‡å®šæ–¹å‘
df = pd.read_json('data.json', orient='records')

# ä»å­—ç¬¦ä¸²è¯»å–
json_str = '{"name": "Alice", "age": 25}'
df = pd.read_json(json_str, typ='series')

# è¯»å–åµŒå¥—JSON
df = pd.json_normalize(json_data)
```

### 3.2 å†™å…¥JSON

```python
# å†™å…¥JSONæ–‡ä»¶
df.to_json('output.json')

# æŒ‡å®šæ–¹å‘
df.to_json('output.json', orient='records')

# æ ¼å¼åŒ–è¾“å‡º
df.to_json('output.json', indent=4)

# è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
json_str = df.to_json()
```

## 4. æ•°æ®åº“æ“ä½œ

### 4.1 SQLite

```python
import sqlite3

# è¿æ¥æ•°æ®åº“
conn = sqlite3.connect('database.db')

# è¯»å–æ•°æ®
df = pd.read_sql('SELECT * FROM table_name', conn)

# è¯»å–æŸ¥è¯¢
query = '''
SELECT name, age 
FROM users 
WHERE age > 25
'''
df = pd.read_sql(query, conn)

# å†™å…¥æ•°æ®åº“
df.to_sql('table_name', conn, if_exists='replace', index=False)

# å…³é—­è¿æ¥
conn.close()
```

### 4.2 MySQL

```python
# éœ€è¦å®‰è£…ï¼špip install pymysql sqlalchemy

from sqlalchemy import create_engine

# åˆ›å»ºå¼•æ“
engine = create_engine('mysql+pymysql://user:password@localhost/database')

# è¯»å–æ•°æ®
df = pd.read_sql('SELECT * FROM table_name', engine)

# å†™å…¥æ•°æ®
df.to_sql('table_name', engine, if_exists='append', index=False)
```

## 5. å…¶ä»–æ ¼å¼

### 5.1 HTML

```python
# è¯»å–HTMLè¡¨æ ¼
dfs = pd.read_html('data.html')

# ä»URLè¯»å–
dfs = pd.read_html('https://example.com/table.html')

# å†™å…¥HTML
df.to_html('output.html', index=False)
```

### 5.2 Parquet

```python
# éœ€è¦å®‰è£…ï¼špip install pyarrow

# è¯»å–Parquet
df = pd.read_parquet('data.parquet')

# å†™å…¥Parquet
df.to_parquet('output.parquet')
```

### 5.3 HDF5

```python
# å†™å…¥HDF5
df.to_hdf('data.h5', key='df', mode='w')

# è¯»å–HDF5
df = pd.read_hdf('data.h5', key='df')
```

## 6. å®æˆ˜ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šæ‰¹é‡å¤„ç†CSVæ–‡ä»¶

```python
import glob

# è¯»å–ç›®å½•ä¸‹æ‰€æœ‰CSVæ–‡ä»¶
files = glob.glob('data/*.csv')

# åˆå¹¶æ‰€æœ‰æ–‡ä»¶
dfs = [pd.read_csv(f) for f in files]
combined_df = pd.concat(dfs, ignore_index=True)

print(f'åˆå¹¶äº† {len(files)} ä¸ªæ–‡ä»¶')
print(f'æ€»è¡Œæ•°: {len(combined_df)}')
```

### ç¤ºä¾‹2ï¼šåˆ†å—è¯»å–å¤§æ–‡ä»¶

```python
# åˆ†å—è¯»å–
chunk_size = 10000
chunks = []

for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    # å¤„ç†æ¯ä¸ªå—
    processed = chunk[chunk['value'] > 0]
    chunks.append(processed)

# åˆå¹¶ç»“æœ
result = pd.concat(chunks, ignore_index=True)
```

### ç¤ºä¾‹3ï¼šæ•°æ®å¯¼å‡ºæŠ¥è¡¨

```python
# åˆ›å»ºæ•°æ®
sales_data = pd.DataFrame({
    'product': ['A', 'B', 'C'],
    'sales': [100, 200, 150],
    'profit': [20, 40, 30]
})

# å¯¼å‡ºåˆ°Excelï¼ˆå¤šä¸ªå·¥ä½œè¡¨ï¼‰
with pd.ExcelWriter('sales_report.xlsx', engine='openpyxl') as writer:
    # åŸå§‹æ•°æ®
    sales_data.to_excel(writer, sheet_name='Raw Data', index=False)
    
    # æ±‡æ€»ç»Ÿè®¡
    summary = sales_data.describe()
    summary.to_excel(writer, sheet_name='Summary')
    
    # é€è§†è¡¨
    pivot = sales_data.pivot_table(values='sales', aggfunc='sum')
    pivot.to_excel(writer, sheet_name='Pivot')
```

## 7. æ€§èƒ½ä¼˜åŒ–

```python
# æŒ‡å®šæ•°æ®ç±»å‹å‡å°‘å†…å­˜
dtypes = {
    'id': 'int32',
    'value': 'float32',
    'category': 'category'
}
df = pd.read_csv('data.csv', dtype=dtypes)

# ä½¿ç”¨categoryç±»å‹
df['category'] = df['category'].astype('category')

# åªè¯»å–éœ€è¦çš„åˆ—
df = pd.read_csv('data.csv', usecols=['col1', 'col2'])

# ä½¿ç”¨Parquetæ ¼å¼ï¼ˆæ›´å¿«ã€æ›´å°ï¼‰
df.to_parquet('data.parquet', compression='snappy')
df = pd.read_parquet('data.parquet')
```

## ç»ƒä¹ é¢˜

1. è¯»å–CSVæ–‡ä»¶å¹¶æŸ¥çœ‹å‰10è¡Œ
2. å°†DataFrameå¯¼å‡ºä¸ºExcelï¼ˆä¸åŒ…å«ç´¢å¼•ï¼‰
3. ä»SQLiteæ•°æ®åº“è¯»å–æ•°æ®
4. åˆå¹¶å¤šä¸ªCSVæ–‡ä»¶

---

**ä¸‹ä¸€èŠ‚ï¼š** [æ•°æ®é€‰æ‹©ä¸ç´¢å¼•](03-æ•°æ®é€‰æ‹©ä¸ç´¢å¼•.md)
