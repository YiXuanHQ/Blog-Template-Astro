---
title: è¯­éŸ³è¯†åˆ«ä¸åˆæˆ
date: 2025-01-22
prevChapter: "harmonyos-dev/09-ai-native/02-AI-Engine-API"
nextChapter: "harmonyos-dev/09-ai-native/04-å›¾åƒè¯†åˆ«ä¸å¤„ç†"
parentChapter: "harmonyos-dev/09-ai-native/README"
---
# è¯­éŸ³è¯†åˆ«ä¸åˆæˆ

> å®ç°è¯­éŸ³äº¤äº’åŠŸèƒ½

## ğŸ¤ è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰

### åŸºç¡€è¯­éŸ³è¯†åˆ«

```typescript
import { speechRecognizer } from '@ohos.ai.speech'

// åˆ›å»ºè¯†åˆ«å™¨
const recognizer = speechRecognizer.create({
  language: 'zh-CN',
  continuous: true,
  enablePunctuation: true
})

// å¼€å§‹è¯†åˆ«
recognizer.start()

// ç›‘å¬è¯†åˆ«ç»“æœ
recognizer.on('result', (result) => {
  console.log('è¯†åˆ«ç»“æœ:', result.text)
  console.log('ç½®ä¿¡åº¦:', result.confidence)
})

// ç›‘å¬é”™è¯¯
recognizer.on('error', (err) => {
  console.error('è¯†åˆ«é”™è¯¯:', err)
})

// åœæ­¢è¯†åˆ«
recognizer.stop()
```

### å®æ—¶è¯­éŸ³è¯†åˆ«

```typescript
@Entry
@Component
struct VoiceRecognition {
  @State transcript: string = ''
  @State isListening: boolean = false
  private recognizer: SpeechRecognizer
  
  startListening() {
    this.recognizer = speechRecognizer.create({
      language: 'zh-CN',
      continuous: true
    })
    
    this.recognizer.on('result', (result) => {
      this.transcript = result.text
    })
    
    this.recognizer.on('partialResult', (result) => {
      // å®æ—¶æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
      this.transcript = result.text
    })
    
    this.recognizer.start()
    this.isListening = true
  }
  
  stopListening() {
    this.recognizer.stop()
    this.isListening = false
  }
  
  build() {
    Column({ space: 20 }) {
      Text(this.transcript || 'è¯·è¯´è¯...')
        .fontSize(18)
        .padding(20)
        .backgroundColor(0xF5F5F5)
        .width('100%')
        .minHeight(100)
      
      Button(this.isListening ? 'åœæ­¢' : 'å¼€å§‹è¯†åˆ«')
        .width(200)
        .onClick(() => {
          if (this.isListening) {
            this.stopListening()
          } else {
            this.startListening()
          }
        })
    }
    .padding(20)
  }
}
```

## ğŸ”Š è¯­éŸ³åˆæˆï¼ˆTTSï¼‰

### åŸºç¡€è¯­éŸ³åˆæˆ

```typescript
import { textToSpeech } from '@ohos.ai.speech'

// åˆ›å»ºåˆæˆå™¨
const tts = textToSpeech.create({
  language: 'zh-CN',
  voice: 'female',
  speed: 1.0,
  pitch: 1.0
})

// åˆæˆè¯­éŸ³
await tts.speak('ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨è¯­éŸ³åŠ©æ‰‹')

// ç›‘å¬åˆæˆè¿›åº¦
tts.on('progress', (progress) => {
  console.log('åˆæˆè¿›åº¦:', progress)
})

// ç›‘å¬å®Œæˆ
tts.on('complete', () => {
  console.log('åˆæˆå®Œæˆ')
})

// åœæ­¢åˆæˆ
tts.stop()
```

### è¯­éŸ³æ’­æŠ¥

```typescript
@Entry
@Component
struct TextToSpeech {
  @State text: string = ''
  @State isSpeaking: boolean = false
  private tts: TTS
  
  async speak() {
    if (!this.text.trim()) return
    
    this.tts = textToSpeech.create({
      language: 'zh-CN',
      voice: 'female',
      speed: 1.0
    })
    
    this.tts.on('start', () => {
      this.isSpeaking = true
    })
    
    this.tts.on('complete', () => {
      this.isSpeaking = false
    })
    
    await this.tts.speak(this.text)
  }
  
  stop() {
    if (this.tts) {
      this.tts.stop()
      this.isSpeaking = false
    }
  }
  
  build() {
    Column({ space: 20 }) {
      TextArea({ placeholder: 'è¾“å…¥è¦æœ—è¯»çš„æ–‡æœ¬' })
        .height(200)
        .onChange((value) => {
          this.text = value
        })
      
      Row({ space: 10 }) {
        Button('æœ—è¯»')
          .onClick(() => {
            this.speak()
          })
        
        Button('åœæ­¢')
          .onClick(() => {
            this.stop()
          })
          .enabled(this.isSpeaking)
      }
    }
    .padding(20)
  }
}
```

## ğŸ¯ å®æˆ˜æ¡ˆä¾‹ï¼šè¯­éŸ³åŠ©æ‰‹

```typescript
@Entry
@Component
struct VoiceAssistant {
  @State transcript: string = ''
  @State response: string = ''
  @State isListening: boolean = false
  private recognizer: SpeechRecognizer
  private tts: TTS
  
  async startVoiceCommand() {
    // è¯­éŸ³è¯†åˆ«
    this.recognizer = speechRecognizer.create({
      language: 'zh-CN'
    })
    
    this.recognizer.on('result', async (result) => {
      this.transcript = result.text
      
      // å¤„ç†å‘½ä»¤
      const response = await this.processCommand(result.text)
      this.response = response
      
      // è¯­éŸ³æ’­æŠ¥
      this.speak(response)
    })
    
    this.recognizer.start()
    this.isListening = true
  }
  
  async processCommand(command: string): Promise<string> {
    if (command.includes('å¤©æ°”')) {
      return 'ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦25åº¦'
    } else if (command.includes('æ—¶é—´')) {
      const now = new Date()
      return `ç°åœ¨æ˜¯${now.getHours()}ç‚¹${now.getMinutes()}åˆ†`
    } else {
      return 'æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„æŒ‡ä»¤'
    }
  }
  
  async speak(text: string) {
    this.tts = textToSpeech.create({
      language: 'zh-CN'
    })
    
    await this.tts.speak(text)
  }
  
  build() {
    Column({ space: 20 }) {
      Text('è¯­éŸ³åŠ©æ‰‹')
        .fontSize(24)
        .fontWeight(FontWeight.Bold)
      
      Column({ space: 10 }) {
        Text('æ‚¨è¯´ï¼š')
          .fontSize(14)
          .fontColor(Color.Gray)
        
        Text(this.transcript || 'ç‚¹å‡»å¼€å§‹è¯´è¯')
          .fontSize(18)
          .padding(15)
          .backgroundColor(0xF5F5F5)
          .width('100%')
          .borderRadius(8)
      }
      
      Column({ space: 10 }) {
        Text('åŠ©æ‰‹å›å¤ï¼š')
          .fontSize(14)
          .fontColor(Color.Gray)
        
        Text(this.response || 'ç­‰å¾…å›å¤')
          .fontSize(18)
          .padding(15)
          .backgroundColor(0xE3F2FD)
          .width('100%')
          .borderRadius(8)
      }
      
      Button(this.isListening ? 'åœæ­¢' : 'å¼€å§‹å¯¹è¯')
        .width(200)
        .height(60)
        .fontSize(18)
        .onClick(() => {
          if (this.isListening) {
            this.recognizer.stop()
            this.isListening = false
          } else {
            this.startVoiceCommand()
          }
        })
    }
    .padding(20)
    .width('100%')
  }
}
```

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. æƒé™ç”³è¯·

```json5
// module.json5
{
  "requestPermissions": [
    {
      "name": "ohos.permission.MICROPHONE",
      "reason": "ç”¨äºè¯­éŸ³è¯†åˆ«"
    }
  ]
}
```

### 2. é™å™ªå¤„ç†

```typescript
const recognizer = speechRecognizer.create({
  enableNoiseReduction: true,  // å¯ç”¨é™å™ª
  enableEchoCancellation: true  // å›å£°æ¶ˆé™¤
})
```

### 3. é”™è¯¯å¤„ç†

```typescript
recognizer.on('error', (err) => {
  if (err.code === 'NO_MICROPHONE') {
    showError('æœªæ£€æµ‹åˆ°éº¦å…‹é£')
  } else if (err.code === 'PERMISSION_DENIED') {
    showError('è¯·æˆäºˆéº¦å…‹é£æƒé™')
  }
})
```

## ğŸ“š å‚è€ƒèµ„æº

- [AIèƒ½åŠ›æ¦‚è¿°](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides-V5/ai-overview-0000001820880597-V5)
- [è¯­éŸ³Kitå‚è€ƒ](https://developer.huawei.com/consumer/cn/doc/harmonyos-references-V5/js-apis-media-0000001821000377-V5)

---

**ä¸‹ä¸€èŠ‚** â†’ [å›¾åƒè¯†åˆ«ä¸å¤„ç†](04-å›¾åƒè¯†åˆ«ä¸å¤„ç†.md)
